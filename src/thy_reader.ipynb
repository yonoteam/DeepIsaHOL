{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333638f4-6408-4a1f-a626-ce5b308716f0",
   "metadata": {},
   "source": [
    "# Theory reader draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d021b26-90d3-4cf0-a51a-561cc930e2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "16b4232a-1314-44fe-bcb4-b06223362e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "thm_kwd_start = ['lemma', 'theorem', 'corollary', 'proposition', 'schematic_goal', 'function', 'termination']\n",
    "prf_kwd_start = ['lemma', 'theorem', 'corollary', 'proposition', 'schematic_goal', 'function', 'termination', 'apply', 'using', 'unfolding', 'then have', 'then show', 'have', 'hence', 'show', 'thus', 'case']\n",
    "thm_rgx_start = re.compile(r'\\b(' + '|'.join(map(re.escape, thm_kwd_start)) + r')\\b')\n",
    "prf_rgx_start = re.compile(r'\\b(' + '|'.join(map(re.escape, prf_kwd_start)) + r')\\b')\n",
    "prf_rgx_end = re.compile(r'\\b(' + '|'.join(map(re.escape, ['by', 'qed', 'done'])) + r')\\b')\n",
    "\n",
    "file_path = 'Test.thy'\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    return lines\n",
    "\n",
    "def proof_starting(line):\n",
    "    return prf_rgx_start.search(line)\n",
    "\n",
    "def proof_ending(line):\n",
    "    return prf_rgx_end.search(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1e6956ec-6950-4dcb-b4c2-287684a1e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strs = read_file(file_path)\n",
    "# test_strs[183:203]\n",
    "# type(thm_rgx_start)\n",
    "test_str = \"\".join(test_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e2a5b5a-cd15-4796-98d9-d7b0f0cdc32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_on_pattern(s, pattern):\n",
    "    # Find all matches and their positions\n",
    "    matches = list(re.finditer(pattern, s))\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    for match in matches:\n",
    "        # End position is the start of the current match\n",
    "        end = match.start()\n",
    "        # Slice the string from start to end and include the matched keyword\n",
    "        chunk = s[start:end] + match.group()\n",
    "        chunks.append(chunk.strip())\n",
    "        # Update start to be just after the current match\n",
    "        start = match.end()\n",
    "    # Append any remaining part of the string\n",
    "    if start < len(s):\n",
    "        chunks.append(s[start:].strip())\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "62384fa1-29f9-4b15-8b43-ef3c532d5951",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = split_on_pattern(test_str, prf_rgx_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "17caa0fb-903d-4833-89ec-6366f577511d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eq_Leaf_map_tree[simp]: \"Leaf = map_tree f t \\\\<longleftrightarrow> t = Leaf\"\\nby (cases t) auto\\n\\n\\nsubsection \\\\<open>\\\\<^const>\\\\<open>size\\\\<close>\\\\<close>\\n\\nlemma']\n"
     ]
    }
   ],
   "source": [
    "print(result[2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5caf5d-55c2-4523-a354-cb4b8a1858eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, match in enumerate(matches):\n",
    "        # End position is the start of the current match\n",
    "        end = match.start()\n",
    "        # Slice the string from start to end (excluding the current match)\n",
    "        chunk = s[start:end].strip()\n",
    "        # Append the chunk to the list\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "        # Update start to be just after the current match\n",
    "        start = match.end()\n",
    "        # If there are more matches, append the matched keyword to the next chunk\n",
    "        if i < len(matches) - 1:\n",
    "            next_match_start = matches[i + 1].start()\n",
    "            chunks[-1] += s[start:next_match_start] + match.group()\n",
    "            start = next_match_start\n",
    "    # Append any remaining part of the string\n",
    "    if start < len(s):\n",
    "        chunks.append(s[start:].strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
